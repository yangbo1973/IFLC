{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e6baba-c3bd-4d22-aea0-fd8c66b64c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import dataloader_clothing1M as dataloader\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "467b41f8-616f-43fc-8c45-333cc21bd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Clothing1M Training')\n",
    "parser.add_argument('--batch_size', default=32, type=int, help='train batchsize') \n",
    "parser.add_argument('--lr', '--learning_rate', default=0.002, type=float, help='initial learning rate')\n",
    "parser.add_argument('--alpha', default=0.5, type=float, help='parameter for Beta')\n",
    "parser.add_argument('--lambda_u', default=0, type=float, help='weight for unsupervised loss')\n",
    "parser.add_argument('--p_threshold', default=0.5, type=float, help='clean probability threshold')\n",
    "parser.add_argument('--T', default=0.5, type=float, help='sharpening temperature')\n",
    "parser.add_argument('--num_epochs', default=80, type=int)\n",
    "parser.add_argument('--id', default='clothing1m')\n",
    "parser.add_argument('--data_path', default='data/Clothing1M/data', type=str, help='path to dataset')\n",
    "parser.add_argument('--seed', default=123)\n",
    "parser.add_argument('--gpuid', default=0, type=int)\n",
    "parser.add_argument('--num_class', default=14, type=int)\n",
    "parser.add_argument('--num_batches', default=1000, type=int)\n",
    "parser.add_argument('--t_w', default=1, type=int)\n",
    "parser.add_argument('--xi', default=0.04, type=float)\n",
    "parser.add_argument('--eta', default=10., type=float)\n",
    "parser.add_argument('--nc', default=1., type=float)\n",
    "parser.add_argument('--nv', default=0.2, type=float)\n",
    "\n",
    "args = parser.parse_args(args = ['--data_path', 'autodl-tmp/clothing1m',\n",
    "                                 '--lambda_u','0',\n",
    "                                 '--lr','0.002',\n",
    "                                 '--batch_size','32',\n",
    "                                 '--num_epochs','100'])\n",
    "\n",
    "torch.cuda.set_device(args.gpuid)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d24a4a3f-2a4a-44d1-aac9-0df3fc01648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_w = args.t_w\n",
    "feature_num = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7889d12e-5124-42e0-bf24-f64c45b99fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Building net\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "def train(epoch,net,net2,optimizer,labeled_trainloader,unlabeled_trainloader,loss_x):\n",
    "    net.train()\n",
    "    net2.eval() #fix one network and train the other\n",
    "    \n",
    "    if not isinstance(loss_x, torch.Tensor):\n",
    "        loss_x = torch.from_numpy(loss_x)\n",
    "    loss_x = (loss_x - loss_x.min()) / (loss_x.max() - loss_x.min())\n",
    "    mask_rand = torch.logical_and(torch.rand(len(loss_x),) >= loss_x, torch.rand(len(loss_x),) < args.xi)\n",
    "    \n",
    "    unlabeled_train_iter = iter(unlabeled_trainloader)    \n",
    "    num_iter = (len(labeled_trainloader.dataset)//args.batch_size)+1\n",
    "    for batch_idx, (ind_x, inputs_x, inputs_x2, labels_x, w_x) in enumerate(labeled_trainloader):      \n",
    "        try:\n",
    "            ind_u, inputs_u, inputs_u2 = unlabeled_train_iter.next()\n",
    "        except:\n",
    "            unlabeled_train_iter = iter(unlabeled_trainloader)\n",
    "            ind_u, inputs_u, inputs_u2 = unlabeled_train_iter.next()                 \n",
    "        batch_size = inputs_x.size(0)\n",
    "        \n",
    "        label_rand = torch.randint(low=0, high = args.num_class, size=labels_x.size())\n",
    "        labels_x = torch.where(mask_rand[ind_x], label_rand, labels_x)\n",
    "        # Transform label to one-hot\n",
    "        labels_x = torch.zeros(batch_size, args.num_class).scatter_(1, labels_x.view(-1,1), 1)        \n",
    "        w_x = w_x.view(-1,1).type(torch.FloatTensor) \n",
    "\n",
    "        inputs_x, inputs_x2, labels_x, w_x = inputs_x.cuda(), inputs_x2.cuda(), labels_x.cuda(), w_x.cuda()\n",
    "        inputs_u, inputs_u2 = inputs_u.cuda(), inputs_u2.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # label co-guessing of unlabeled samples\n",
    "            outputs_u11 = net(inputs_u)\n",
    "            outputs_u12 = net(inputs_u2)\n",
    "            outputs_u21 = net2(inputs_u)\n",
    "            outputs_u22 = net2(inputs_u2)            \n",
    "            \n",
    "            pu = (torch.softmax(outputs_u11, dim=1) + torch.softmax(outputs_u12, dim=1) + torch.softmax(outputs_u21, dim=1) + torch.softmax(outputs_u22, dim=1)) / 4       \n",
    "            ptu = pu**(1/args.T) # temparature sharpening\n",
    "            \n",
    "            targets_u = ptu / ptu.sum(dim=1, keepdim=True) # normalize\n",
    "            targets_u = targets_u.detach()       \n",
    "            \n",
    "            # label refinement of labeled samples\n",
    "            fe_x, outputs_x = forward_wf(net, inputs_x)\n",
    "            outputs_x2 = net(inputs_x2)            \n",
    "            \n",
    "            px = (torch.softmax(outputs_x, dim=1) + torch.softmax(outputs_x2, dim=1)) / 2\n",
    "            px = w_x*labels_x + (1-w_x)*px              \n",
    "            ptx = px**(1/args.T) # temparature sharpening \n",
    "                       \n",
    "            targets_x = ptx / ptx.sum(dim=1, keepdim=True) # normalize           \n",
    "            targets_x = targets_x.detach()       \n",
    "        \n",
    "        # mixmatch\n",
    "        l = np.random.beta(args.alpha, args.alpha)        \n",
    "        l = max(l, 1-l)        \n",
    "        \n",
    "        all_inputs = torch.cat([inputs_x, inputs_x2, inputs_u, inputs_u2], dim=0)\n",
    "        all_targets = torch.cat([targets_x, targets_x, targets_u, targets_u], dim=0)\n",
    "\n",
    "        idx = torch.randperm(all_inputs.size(0))\n",
    "\n",
    "        input_a, input_b = all_inputs, all_inputs[idx]\n",
    "        target_a, target_b = all_targets, all_targets[idx]\n",
    "        \n",
    "        mixed_input = l * input_a[:batch_size*2] + (1 - l) * input_b[:batch_size*2]        \n",
    "        mixed_target = l * target_a[:batch_size*2] + (1 - l) * target_b[:batch_size*2]\n",
    "                \n",
    "        logits = net(mixed_input)\n",
    "        \n",
    "        Lx = -torch.mean(torch.sum(F.log_softmax(logits, dim=1) * mixed_target, dim=1))\n",
    "        \n",
    "        # regularization\n",
    "        prior = torch.ones(args.num_class)/args.num_class\n",
    "        prior = prior.cuda()        \n",
    "        pred_mean = torch.softmax(logits, dim=1).mean(0)\n",
    "        penalty = torch.sum(prior*torch.log(prior/pred_mean))\n",
    "       \n",
    "        loss_o = loss_ortho(fe_x)\n",
    "        \n",
    "        loss = Lx + penalty + loss_o * args.eta\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write('Clothing1M | Epoch [%3d/%3d] Iter[%3d/%3d]\\t  Labeled loss: %.4f \\t loss_o: %.4f'\n",
    "                %(epoch, args.num_epochs, batch_idx+1, num_iter, Lx.item(), loss_o.item()))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "def warmup(net,optimizer,dataloader):\n",
    "    net.train()\n",
    "    for batch_idx, (ind, inputs, labels, path) in enumerate(dataloader):      \n",
    "        inputs, labels = inputs.cuda(), labels.cuda() \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)              \n",
    "        loss = CEloss(outputs, labels)  \n",
    "        \n",
    "        penalty = conf_penalty(outputs)\n",
    "        L = loss + penalty       \n",
    "        L.backward()  \n",
    "        optimizer.step() \n",
    "\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.write('|Warm-up: Iter[%3d/%3d]\\t CE-loss: %.4f  Conf-Penalty: %.4f'\n",
    "                %(batch_idx+1, args.num_batches, loss.item(), penalty.item()))\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "def val(net,val_loader,k):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (ind, inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)         \n",
    "                       \n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).cpu().sum().item()              \n",
    "    acc = 100.*correct/total\n",
    "    print(\"\\n| Validation\\t Net%d  Acc: %.2f%%\" %(k,acc))  \n",
    "    if acc > best_acc[k-1]:\n",
    "        best_acc[k-1] = acc\n",
    "        print('| Saving Best Net%d ...'%k)\n",
    "        save_point = './checkpoint/%s_net%d.pth.tar'%(args.id,k)\n",
    "        torch.save(net.state_dict(), save_point)\n",
    "    return acc\n",
    "\n",
    "def test(net1,net2,test_loader):\n",
    "    net1.eval()\n",
    "    net2.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (ind, inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs1 = net1(inputs)       \n",
    "            outputs2 = net2(inputs)           \n",
    "            outputs = outputs1+outputs2\n",
    "            _, predicted = torch.max(outputs, 1)            \n",
    "                       \n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).cpu().sum().item()                    \n",
    "    acc = 100.*correct/total\n",
    "    print(\"\\n| Test Acc: %.2f%%\\n\" %(acc))  \n",
    "    return acc    \n",
    "\n",
    "\n",
    "def eval_train(model,):\n",
    "    model.eval()\n",
    "\n",
    "    num_samples = args.num_batches*args.batch_size\n",
    "    losses = np.zeros(num_samples)\n",
    "    feature_temp = np.zeros((num_samples, feature_num),)\n",
    "    noise_label = np.zeros(num_samples, dtype = np.int64)\n",
    "    paths = []\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (ind, inputs, targets, path) in enumerate(eval_loader):\n",
    "            noise_label[ind] = targets.detach().numpy()\n",
    "            inputs, targets = inputs.cuda(), targets.cuda() \n",
    "            feature, outputs = forward_wf(model, inputs) \n",
    "            loss = CE(outputs, targets)  \n",
    "            losses[ind] = loss.cpu().detach().numpy()\n",
    "            feature_temp[ind] = feature.cpu().detach().numpy()\n",
    "            \n",
    "            for b in range(inputs.size(0)):\n",
    "                paths.append(path[b])\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.write('| Evaluating loss Iter %3d\\t' %(batch_idx)) \n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    Y_onehot = np.eye(args.num_class)[noise_label]\n",
    "    \n",
    "    losses = (losses-losses.min())/(losses.max()-losses.min())    \n",
    "    losses = losses.ravel()\n",
    "    \n",
    "    if args.nc < 1:\n",
    "        clean_mask = np.zeros((num_samples,),dtype = np.bool)\n",
    "        for j_ in range(args.num_class):\n",
    "            class_mask = np.array(noise_label) == j_\n",
    "            c_n = class_mask.sum()\n",
    "            if c_n > 1:\n",
    "                thres = np.sort(losses[class_mask])[int((c_n-1) * args.nc)]\n",
    "                clean_mask[np.logical_and(losses < thres, class_mask)] = True\n",
    "        feature_gpu = torch.from_numpy(feature_temp[clean_mask]).cuda()\n",
    "\n",
    "        Y_onehot_gpu = torch.from_numpy(Y_onehot[clean_mask]).cuda()\n",
    "    else:\n",
    "        feature_gpu = torch.from_numpy(feature_temp).cuda()\n",
    "        Y_onehot_gpu = torch.from_numpy(Y_onehot).cuda()\n",
    "\n",
    "    W = torch.linalg.lstsq(feature_gpu, Y_onehot_gpu).solution\n",
    "    W_cpu = W.cpu().detach().numpy()\n",
    "\n",
    "    f_prob = feature_temp @ W_cpu   \n",
    "    \n",
    "    score = np.sum((Y_onehot - f_prob) ** 2, axis = -1)\n",
    "            \n",
    "    prob = 1 - score\n",
    "    prob = (prob-prob.min())/(prob.max()-prob.min())  \n",
    "        \n",
    "    return prob, losses, paths  \n",
    "\n",
    "\n",
    "class NegEntropy(object):\n",
    "    def __call__(self,outputs):\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        return torch.mean(torch.sum(probs.log()*probs, dim=1))\n",
    "\n",
    "    \n",
    "class Orthogonal_loss(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(Orthogonal_loss, self).__init__()\n",
    "        \n",
    "    def forward(self, x, ):\n",
    "        n = x.size(0)\n",
    "        m = x.size(1)\n",
    "\n",
    "        I = torch.eye(m).cuda()\n",
    "        e = x - x.mean(dim=0, keepdims = True)\n",
    "        m_nonz = (e.sum(dim = 0) != 0).sum()\n",
    "        \n",
    "        cov = e.T @ e\n",
    "        \n",
    "        cov2 = cov ** 2\n",
    "        \n",
    "        select_i = torch.argmax(cov2 - cov2 * I, dim = 1)\n",
    "        cov_m = (F.one_hot(select_i, num_classes = m) * cov2).sum()\n",
    "        cov_i = (I * cov).sum()\n",
    "        \n",
    "        result = (cov_m-cov_i) / (m_nonz*n)\n",
    "        return result\n",
    "    \n",
    "def create_model():\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(2048,args.num_class)\n",
    "    model = model.cuda()\n",
    "    return model     \n",
    "\n",
    "def forward_wf(net, x):\n",
    "    import torch.nn.functional as F\n",
    "    out = x\n",
    "    out = net.conv1(out)\n",
    "    out = net.bn1(out)\n",
    "    out = F.relu(out)\n",
    "    \n",
    "    out = net.layer1(out)\n",
    "    out = net.layer2(out)\n",
    "    out = net.layer3(out)\n",
    "    out = net.layer4(out)\n",
    "    out = F.adaptive_avg_pool2d(out, (1,1))\n",
    "    feature = out.view(out.size(0), -1)\n",
    "    out = net.fc(feature)\n",
    "    \n",
    "    return feature, out\n",
    "\n",
    "log=open('./checkpoint/%s_%s.txt'%(args.id,str(datetime.datetime.now().date())+'-'+str(datetime.datetime.now().hour)),'w')     \n",
    "log.flush()\n",
    "\n",
    "loader = dataloader.clothing_dataloader(root=args.data_path,batch_size=args.batch_size,num_workers=5,num_batches=args.num_batches)\n",
    "\n",
    "print('| Building net')\n",
    "net1 = create_model()\n",
    "net2 = create_model()\n",
    "cudnn.benchmark = True\n",
    "\n",
    "optimizer1 = optim.SGD(net1.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-3)\n",
    "optimizer2 = optim.SGD(net2.parameters(), lr=args.lr, momentum=0.9, weight_decay=1e-3)\n",
    "\n",
    "scheduler1 = optim.lr_scheduler.MultiStepLR(optimizer1, milestones=[40,80], gamma=0.1)\n",
    "scheduler2 = optim.lr_scheduler.MultiStepLR(optimizer2, milestones=[40,80], gamma=0.1)\n",
    "                      \n",
    "CE = nn.CrossEntropyLoss(reduction='none')\n",
    "CEloss = nn.CrossEntropyLoss()\n",
    "conf_penalty = NegEntropy()\n",
    "\n",
    "loss_ortho = Orthogonal_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e9fda7-ddeb-4142-9f63-280f18ac7bbf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup Net1\n",
      "|Warm-up: Iter[1000/1000]\t CE-loss: 1.3454  Conf-Penalty: -2.1645\n",
      "Warmup Net2\n",
      "|Warm-up: Iter[1000/1000]\t CE-loss: 1.5236  Conf-Penalty: -2.2743\n",
      "| Validation\t Net1  Acc: 68.24%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 67.04%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_215191/3484871656.py:205: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  clean_mask = np.zeros((num_samples,),dtype = np.bool)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  1/100] Iter[800/800]\t  Labeled loss: 1.1372 \t loss_o: 0.0334\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  1/100] Iter[800/800]\t  Labeled loss: 0.6710 \t loss_o: 0.0336\n",
      "| Validation\t Net1  Acc: 68.23%\n",
      "\n",
      "| Validation\t Net2  Acc: 69.49%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  2/100] Iter[800/800]\t  Labeled loss: 0.7295 \t loss_o: 0.0372\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  2/100] Iter[800/800]\t  Labeled loss: 0.5033 \t loss_o: 0.0293\n",
      "| Validation\t Net1  Acc: 70.15%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 70.26%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  3/100] Iter[800/800]\t  Labeled loss: 0.6993 \t loss_o: 0.0375\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  3/100] Iter[800/800]\t  Labeled loss: 0.9783 \t loss_o: 0.0245\n",
      "| Validation\t Net1  Acc: 71.10%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 71.54%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  4/100] Iter[800/800]\t  Labeled loss: 1.0442 \t loss_o: 0.0080\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  4/100] Iter[800/800]\t  Labeled loss: 0.9152 \t loss_o: 0.0478\n",
      "| Validation\t Net1  Acc: 71.40%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 71.48%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  5/100] Iter[800/800]\t  Labeled loss: 0.4852 \t loss_o: 0.0241\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  5/100] Iter[800/800]\t  Labeled loss: 1.2951 \t loss_o: 0.0192\n",
      "| Validation\t Net1  Acc: 71.79%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 71.98%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  6/100] Iter[800/800]\t  Labeled loss: 1.7692 \t loss_o: 0.0113\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  6/100] Iter[800/800]\t  Labeled loss: 1.5341 \t loss_o: 0.0022\n",
      "| Validation\t Net1  Acc: 72.57%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 71.91%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  7/100] Iter[800/800]\t  Labeled loss: 1.3464 \t loss_o: 0.0197\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  7/100] Iter[800/800]\t  Labeled loss: 0.7171 \t loss_o: 0.0217\n",
      "| Validation\t Net1  Acc: 72.35%\n",
      "\n",
      "| Validation\t Net2  Acc: 71.74%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  8/100] Iter[800/800]\t  Labeled loss: 1.1690 \t loss_o: 0.01977\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  8/100] Iter[800/800]\t  Labeled loss: 1.2998 \t loss_o: 0.0198\n",
      "| Validation\t Net1  Acc: 72.32%\n",
      "\n",
      "| Validation\t Net2  Acc: 71.86%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  9/100] Iter[800/800]\t  Labeled loss: 0.9581 \t loss_o: 0.00924\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [  9/100] Iter[800/800]\t  Labeled loss: 1.6493 \t loss_o: 0.02216\n",
      "| Validation\t Net1  Acc: 72.00%\n",
      "\n",
      "| Validation\t Net2  Acc: 71.96%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 10/100] Iter[800/800]\t  Labeled loss: 1.5972 \t loss_o: 0.00233\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 10/100] Iter[800/800]\t  Labeled loss: 0.3421 \t loss_o: 0.02448\n",
      "| Validation\t Net1  Acc: 72.63%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 72.69%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 11/100] Iter[800/800]\t  Labeled loss: 1.5248 \t loss_o: 0.00281\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 11/100] Iter[800/800]\t  Labeled loss: 1.1195 \t loss_o: 0.00963\n",
      "| Validation\t Net1  Acc: 71.64%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.13%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 12/100] Iter[800/800]\t  Labeled loss: 0.5825 \t loss_o: 0.00792\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 12/100] Iter[800/800]\t  Labeled loss: 1.0231 \t loss_o: 0.00011\n",
      "| Validation\t Net1  Acc: 72.33%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.42%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 13/100] Iter[800/800]\t  Labeled loss: 0.7297 \t loss_o: 0.00571\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 13/100] Iter[800/800]\t  Labeled loss: 0.5869 \t loss_o: 0.00992\n",
      "| Validation\t Net1  Acc: 72.25%\n",
      "\n",
      "| Validation\t Net2  Acc: 71.85%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 14/100] Iter[800/800]\t  Labeled loss: 0.5427 \t loss_o: -0.0006\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 14/100] Iter[800/800]\t  Labeled loss: 1.0324 \t loss_o: 0.00329\n",
      "| Validation\t Net1  Acc: 72.44%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.21%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 15/100] Iter[800/800]\t  Labeled loss: 0.8469 \t loss_o: -0.0016\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 15/100] Iter[800/800]\t  Labeled loss: 1.6747 \t loss_o: -0.0022\n",
      "| Validation\t Net1  Acc: 72.74%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 72.77%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 16/100] Iter[800/800]\t  Labeled loss: 1.5080 \t loss_o: 0.00339\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 16/100] Iter[800/800]\t  Labeled loss: 1.3574 \t loss_o: 0.00659\n",
      "| Validation\t Net1  Acc: 72.74%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.89%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 17/100] Iter[800/800]\t  Labeled loss: 1.6333 \t loss_o: -0.0013\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 17/100] Iter[800/800]\t  Labeled loss: 0.9979 \t loss_o: -0.0022\n",
      "| Validation\t Net1  Acc: 72.71%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.58%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 18/100] Iter[800/800]\t  Labeled loss: 1.6166 \t loss_o: 0.02071\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 18/100] Iter[800/800]\t  Labeled loss: 0.7023 \t loss_o: -0.0034\n",
      "| Validation\t Net1  Acc: 72.40%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.66%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 19/100] Iter[800/800]\t  Labeled loss: 0.5268 \t loss_o: 0.00416\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 19/100] Iter[800/800]\t  Labeled loss: 1.7249 \t loss_o: 0.00104\n",
      "| Validation\t Net1  Acc: 72.80%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 72.68%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 20/100] Iter[800/800]\t  Labeled loss: 1.5183 \t loss_o: -0.0041\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 20/100] Iter[800/800]\t  Labeled loss: 1.1581 \t loss_o: -0.0049\n",
      "| Validation\t Net1  Acc: 73.43%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 72.64%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 21/100] Iter[800/800]\t  Labeled loss: 1.1374 \t loss_o: -0.0007\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 21/100] Iter[800/800]\t  Labeled loss: 1.5385 \t loss_o: 0.00226\n",
      "| Validation\t Net1  Acc: 72.44%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.57%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 22/100] Iter[800/800]\t  Labeled loss: 1.8264 \t loss_o: 0.00066\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 22/100] Iter[800/800]\t  Labeled loss: 0.8233 \t loss_o: -0.0031\n",
      "| Validation\t Net1  Acc: 73.09%\n",
      "\n",
      "| Validation\t Net2  Acc: 71.96%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 23/100] Iter[800/800]\t  Labeled loss: 1.9733 \t loss_o: -0.0000\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 23/100] Iter[800/800]\t  Labeled loss: 1.8257 \t loss_o: -0.0031\n",
      "| Validation\t Net1  Acc: 72.91%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.11%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 24/100] Iter[800/800]\t  Labeled loss: 1.2356 \t loss_o: 0.00182\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 24/100] Iter[800/800]\t  Labeled loss: 0.4433 \t loss_o: -0.0035\n",
      "| Validation\t Net1  Acc: 73.13%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.96%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 25/100] Iter[800/800]\t  Labeled loss: 1.6072 \t loss_o: 0.00467\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 25/100] Iter[800/800]\t  Labeled loss: 1.7197 \t loss_o: -0.0021\n",
      "| Validation\t Net1  Acc: 73.14%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.77%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 26/100] Iter[800/800]\t  Labeled loss: 0.3097 \t loss_o: 0.00416\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 26/100] Iter[800/800]\t  Labeled loss: 0.7453 \t loss_o: -0.0014\n",
      "| Validation\t Net1  Acc: 72.65%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.24%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 27/100] Iter[800/800]\t  Labeled loss: 1.3495 \t loss_o: -0.0019\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 27/100] Iter[800/800]\t  Labeled loss: 0.5271 \t loss_o: -0.0028\n",
      "| Validation\t Net1  Acc: 72.61%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.80%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 28/100] Iter[800/800]\t  Labeled loss: 1.7225 \t loss_o: -0.0041\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 28/100] Iter[800/800]\t  Labeled loss: 1.4457 \t loss_o: -0.0021\n",
      "| Validation\t Net1  Acc: 72.71%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.51%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 29/100] Iter[800/800]\t  Labeled loss: 0.8394 \t loss_o: 0.00092\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 29/100] Iter[800/800]\t  Labeled loss: 1.8152 \t loss_o: -0.0035\n",
      "| Validation\t Net1  Acc: 71.50%\n",
      "\n",
      "| Validation\t Net2  Acc: 71.97%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 30/100] Iter[800/800]\t  Labeled loss: 1.6824 \t loss_o: -0.0026\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 30/100] Iter[800/800]\t  Labeled loss: 1.0492 \t loss_o: -0.0007\n",
      "| Validation\t Net1  Acc: 72.58%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.98%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 31/100] Iter[800/800]\t  Labeled loss: 1.2267 \t loss_o: -0.0013\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 31/100] Iter[800/800]\t  Labeled loss: 1.7115 \t loss_o: -0.0041\n",
      "| Validation\t Net1  Acc: 72.74%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.82%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 32/100] Iter[800/800]\t  Labeled loss: 1.2645 \t loss_o: -0.0017\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 32/100] Iter[800/800]\t  Labeled loss: 0.8164 \t loss_o: -0.0032\n",
      "| Validation\t Net1  Acc: 72.70%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.75%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 33/100] Iter[800/800]\t  Labeled loss: 0.6061 \t loss_o: -0.0041\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 33/100] Iter[800/800]\t  Labeled loss: 1.4757 \t loss_o: -0.0049\n",
      "| Validation\t Net1  Acc: 72.80%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.97%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 34/100] Iter[800/800]\t  Labeled loss: 1.4601 \t loss_o: -0.0038\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 34/100] Iter[800/800]\t  Labeled loss: 0.9317 \t loss_o: -0.0044\n",
      "| Validation\t Net1  Acc: 71.93%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.99%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 35/100] Iter[800/800]\t  Labeled loss: 0.5533 \t loss_o: -0.0046\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 35/100] Iter[800/800]\t  Labeled loss: 1.5950 \t loss_o: -0.0032\n",
      "| Validation\t Net1  Acc: 72.07%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.07%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 36/100] Iter[800/800]\t  Labeled loss: 0.9243 \t loss_o: -0.0043\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 36/100] Iter[800/800]\t  Labeled loss: 1.4448 \t loss_o: -0.0052\n",
      "| Validation\t Net1  Acc: 72.40%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.15%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 37/100] Iter[800/800]\t  Labeled loss: 1.6464 \t loss_o: -0.0022\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 37/100] Iter[800/800]\t  Labeled loss: 0.6102 \t loss_o: -0.0052\n",
      "| Validation\t Net1  Acc: 72.37%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.14%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 38/100] Iter[800/800]\t  Labeled loss: 0.5061 \t loss_o: -0.0037\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 38/100] Iter[800/800]\t  Labeled loss: 0.3097 \t loss_o: -0.0038\n",
      "| Validation\t Net1  Acc: 72.43%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.04%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 39/100] Iter[800/800]\t  Labeled loss: 0.4765 \t loss_o: -0.0041\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 39/100] Iter[800/800]\t  Labeled loss: 0.7671 \t loss_o: -0.0045\n",
      "| Validation\t Net1  Acc: 72.41%\n",
      "\n",
      "| Validation\t Net2  Acc: 72.33%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 40/100] Iter[800/800]\t  Labeled loss: 0.8133 \t loss_o: -0.0024\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 40/100] Iter[800/800]\t  Labeled loss: 1.6067 \t loss_o: -0.0043\n",
      "| Validation\t Net1  Acc: 72.95%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.77%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 41/100] Iter[800/800]\t  Labeled loss: 1.5393 \t loss_o: -0.0049\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 41/100] Iter[800/800]\t  Labeled loss: 1.8603 \t loss_o: -0.0039\n",
      "| Validation\t Net1  Acc: 73.74%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 73.78%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 42/100] Iter[800/800]\t  Labeled loss: 1.3415 \t loss_o: -0.0054\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 42/100] Iter[800/800]\t  Labeled loss: 0.9170 \t loss_o: -0.0052\n",
      "| Validation\t Net1  Acc: 73.67%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.93%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 43/100] Iter[800/800]\t  Labeled loss: 0.5481 \t loss_o: -0.0042\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 43/100] Iter[800/800]\t  Labeled loss: 1.4854 \t loss_o: -0.0048\n",
      "| Validation\t Net1  Acc: 73.52%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.25%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 44/100] Iter[800/800]\t  Labeled loss: 0.9543 \t loss_o: -0.0010\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 44/100] Iter[800/800]\t  Labeled loss: 1.2462 \t loss_o: -0.0043\n",
      "| Validation\t Net1  Acc: 73.88%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.62%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 45/100] Iter[800/800]\t  Labeled loss: 1.6867 \t loss_o: -0.0034\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 45/100] Iter[800/800]\t  Labeled loss: 1.5871 \t loss_o: -0.0031\n",
      "| Validation\t Net1  Acc: 74.32%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.23%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 46/100] Iter[800/800]\t  Labeled loss: 0.9194 \t loss_o: -0.0039\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 46/100] Iter[800/800]\t  Labeled loss: 1.5668 \t loss_o: -0.0050\n",
      "| Validation\t Net1  Acc: 74.04%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.37%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 47/100] Iter[800/800]\t  Labeled loss: 1.7629 \t loss_o: -0.0038\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 47/100] Iter[800/800]\t  Labeled loss: 0.6016 \t loss_o: -0.0040\n",
      "| Validation\t Net1  Acc: 74.03%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.13%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 48/100] Iter[800/800]\t  Labeled loss: 1.6983 \t loss_o: -0.0049\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 48/100] Iter[800/800]\t  Labeled loss: 0.5945 \t loss_o: -0.0041\n",
      "| Validation\t Net1  Acc: 73.85%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.00%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 49/100] Iter[800/800]\t  Labeled loss: 1.3159 \t loss_o: -0.0015\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 49/100] Iter[800/800]\t  Labeled loss: 0.6625 \t loss_o: -0.0042\n",
      "| Validation\t Net1  Acc: 74.42%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.46%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 50/100] Iter[800/800]\t  Labeled loss: 0.4669 \t loss_o: -0.0051\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 50/100] Iter[800/800]\t  Labeled loss: 1.1115 \t loss_o: -0.0053\n",
      "| Validation\t Net1  Acc: 74.44%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.25%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 51/100] Iter[800/800]\t  Labeled loss: 1.5123 \t loss_o: -0.0045\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 51/100] Iter[800/800]\t  Labeled loss: 1.4693 \t loss_o: -0.0039\n",
      "| Validation\t Net1  Acc: 74.21%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.21%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 52/100] Iter[800/800]\t  Labeled loss: 0.8481 \t loss_o: -0.0041\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 52/100] Iter[800/800]\t  Labeled loss: 0.8599 \t loss_o: -0.0026\n",
      "| Validation\t Net1  Acc: 74.41%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.25%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 53/100] Iter[800/800]\t  Labeled loss: 0.3229 \t loss_o: -0.0044\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 53/100] Iter[800/800]\t  Labeled loss: 0.4587 \t loss_o: -0.0027\n",
      "| Validation\t Net1  Acc: 74.43%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.66%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 54/100] Iter[800/800]\t  Labeled loss: 0.5908 \t loss_o: -0.0042\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 54/100] Iter[800/800]\t  Labeled loss: 0.3977 \t loss_o: -0.0052\n",
      "| Validation\t Net1  Acc: 74.38%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.15%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 55/100] Iter[800/800]\t  Labeled loss: 1.2500 \t loss_o: -0.0043\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 55/100] Iter[800/800]\t  Labeled loss: 1.0348 \t loss_o: -0.0044\n",
      "| Validation\t Net1  Acc: 74.60%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.22%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 56/100] Iter[800/800]\t  Labeled loss: 1.3256 \t loss_o: -0.0051\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 56/100] Iter[800/800]\t  Labeled loss: 0.7812 \t loss_o: -0.0033\n",
      "| Validation\t Net1  Acc: 74.10%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.29%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 57/100] Iter[800/800]\t  Labeled loss: 1.0982 \t loss_o: -0.0041\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 57/100] Iter[800/800]\t  Labeled loss: 0.6019 \t loss_o: -0.0036\n",
      "| Validation\t Net1  Acc: 74.13%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.74%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 58/100] Iter[800/800]\t  Labeled loss: 1.4030 \t loss_o: -0.0024\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 58/100] Iter[800/800]\t  Labeled loss: 1.9057 \t loss_o: -0.0041\n",
      "| Validation\t Net1  Acc: 74.58%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.39%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 59/100] Iter[800/800]\t  Labeled loss: 0.3376 \t loss_o: -0.0037\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 59/100] Iter[800/800]\t  Labeled loss: 0.5623 \t loss_o: -0.0052\n",
      "| Validation\t Net1  Acc: 74.44%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.95%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 60/100] Iter[800/800]\t  Labeled loss: 1.4729 \t loss_o: -0.0040\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 60/100] Iter[800/800]\t  Labeled loss: 1.6431 \t loss_o: -0.0046\n",
      "| Validation\t Net1  Acc: 74.49%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.34%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 61/100] Iter[800/800]\t  Labeled loss: 0.4985 \t loss_o: -0.0043\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 61/100] Iter[800/800]\t  Labeled loss: 1.0356 \t loss_o: -0.0043\n",
      "| Validation\t Net1  Acc: 74.61%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.38%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 62/100] Iter[800/800]\t  Labeled loss: 1.6152 \t loss_o: -0.0024\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 62/100] Iter[800/800]\t  Labeled loss: 1.2762 \t loss_o: -0.0037\n",
      "| Validation\t Net1  Acc: 74.65%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.29%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 63/100] Iter[800/800]\t  Labeled loss: 0.9437 \t loss_o: -0.0027\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 63/100] Iter[800/800]\t  Labeled loss: 0.6434 \t loss_o: -0.0051\n",
      "| Validation\t Net1  Acc: 74.09%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.09%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 64/100] Iter[800/800]\t  Labeled loss: 0.6624 \t loss_o: -0.0012\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 64/100] Iter[800/800]\t  Labeled loss: 1.5785 \t loss_o: -0.0042\n",
      "| Validation\t Net1  Acc: 74.06%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.95%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 65/100] Iter[800/800]\t  Labeled loss: 1.1685 \t loss_o: -0.0032\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 65/100] Iter[800/800]\t  Labeled loss: 0.9984 \t loss_o: -0.0045\n",
      "| Validation\t Net1  Acc: 74.54%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.58%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 66/100] Iter[800/800]\t  Labeled loss: 0.5879 \t loss_o: -0.0049\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 66/100] Iter[800/800]\t  Labeled loss: 1.0204 \t loss_o: -0.0020\n",
      "| Validation\t Net1  Acc: 74.71%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.15%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 67/100] Iter[800/800]\t  Labeled loss: 1.6710 \t loss_o: -0.0052\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 67/100] Iter[800/800]\t  Labeled loss: 1.7397 \t loss_o: -0.0038\n",
      "| Validation\t Net1  Acc: 74.28%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.54%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 68/100] Iter[800/800]\t  Labeled loss: 1.6863 \t loss_o: -0.0036\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 68/100] Iter[800/800]\t  Labeled loss: 1.3678 \t loss_o: -0.0041\n",
      "| Validation\t Net1  Acc: 74.28%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.62%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 69/100] Iter[800/800]\t  Labeled loss: 0.5879 \t loss_o: -0.0031\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 69/100] Iter[800/800]\t  Labeled loss: 0.4497 \t loss_o: -0.0040\n",
      "| Validation\t Net1  Acc: 74.42%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.80%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 70/100] Iter[800/800]\t  Labeled loss: 0.4329 \t loss_o: -0.0046\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 70/100] Iter[800/800]\t  Labeled loss: 1.3138 \t loss_o: -0.0037\n",
      "| Validation\t Net1  Acc: 73.95%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.44%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 71/100] Iter[800/800]\t  Labeled loss: 1.5706 \t loss_o: -0.0037\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 71/100] Iter[800/800]\t  Labeled loss: 0.7380 \t loss_o: -0.0040\n",
      "| Validation\t Net1  Acc: 73.95%\n",
      "\n",
      "| Validation\t Net2  Acc: 73.83%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 72/100] Iter[800/800]\t  Labeled loss: 1.1373 \t loss_o: -0.0036\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 72/100] Iter[800/800]\t  Labeled loss: 0.4017 \t loss_o: -0.0049\n",
      "| Validation\t Net1  Acc: 74.37%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.77%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 73/100] Iter[800/800]\t  Labeled loss: 1.1533 \t loss_o: -0.0044\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 73/100] Iter[800/800]\t  Labeled loss: 0.7412 \t loss_o: -0.0035\n",
      "| Validation\t Net1  Acc: 74.18%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.47%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 74/100] Iter[800/800]\t  Labeled loss: 1.6408 \t loss_o: -0.0049\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 74/100] Iter[800/800]\t  Labeled loss: 1.5712 \t loss_o: -0.0047\n",
      "| Validation\t Net1  Acc: 74.41%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.34%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 75/100] Iter[800/800]\t  Labeled loss: 1.4991 \t loss_o: -0.0036\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 75/100] Iter[800/800]\t  Labeled loss: 0.4300 \t loss_o: -0.0046\n",
      "| Validation\t Net1  Acc: 73.78%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.81%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 76/100] Iter[800/800]\t  Labeled loss: 1.4741 \t loss_o: -0.0038\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 76/100] Iter[800/800]\t  Labeled loss: 1.5484 \t loss_o: -0.0039\n",
      "| Validation\t Net1  Acc: 74.50%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.72%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 77/100] Iter[800/800]\t  Labeled loss: 0.6127 \t loss_o: -0.0036\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 77/100] Iter[800/800]\t  Labeled loss: 0.4651 \t loss_o: -0.0045\n",
      "| Validation\t Net1  Acc: 74.15%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.67%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 78/100] Iter[800/800]\t  Labeled loss: 1.3816 \t loss_o: -0.0054\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 78/100] Iter[800/800]\t  Labeled loss: 1.3772 \t loss_o: -0.0044\n",
      "| Validation\t Net1  Acc: 74.62%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.76%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 79/100] Iter[800/800]\t  Labeled loss: 0.6869 \t loss_o: -0.0049\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 79/100] Iter[800/800]\t  Labeled loss: 1.3766 \t loss_o: -0.0036\n",
      "| Validation\t Net1  Acc: 74.22%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.07%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 80/100] Iter[800/800]\t  Labeled loss: 1.3759 \t loss_o: -0.0021\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 80/100] Iter[800/800]\t  Labeled loss: 0.9728 \t loss_o: -0.0045\n",
      "| Validation\t Net1  Acc: 74.22%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.88%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 81/100] Iter[800/800]\t  Labeled loss: 1.4917 \t loss_o: -0.0053\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 81/100] Iter[800/800]\t  Labeled loss: 0.2931 \t loss_o: -0.0038\n",
      "| Validation\t Net1  Acc: 74.90%\n",
      "| Saving Best Net1 ...\n",
      "\n",
      "| Validation\t Net2  Acc: 74.55%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 82/100] Iter[800/800]\t  Labeled loss: 0.5959 \t loss_o: -0.0044\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 82/100] Iter[800/800]\t  Labeled loss: 1.3790 \t loss_o: -0.0028\n",
      "| Validation\t Net1  Acc: 74.33%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.81%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 83/100] Iter[800/800]\t  Labeled loss: 0.5907 \t loss_o: -0.0047\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 83/100] Iter[800/800]\t  Labeled loss: 1.4387 \t loss_o: -0.0048\n",
      "| Validation\t Net1  Acc: 74.79%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.70%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 84/100] Iter[800/800]\t  Labeled loss: 0.4619 \t loss_o: -0.0051\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 84/100] Iter[800/800]\t  Labeled loss: 1.3585 \t loss_o: -0.0044\n",
      "| Validation\t Net1  Acc: 74.11%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.93%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 85/100] Iter[800/800]\t  Labeled loss: 0.7764 \t loss_o: -0.0044\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 85/100] Iter[800/800]\t  Labeled loss: 1.3909 \t loss_o: -0.0047\n",
      "| Validation\t Net1  Acc: 74.17%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.46%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 86/100] Iter[800/800]\t  Labeled loss: 0.6120 \t loss_o: -0.0048\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 86/100] Iter[800/800]\t  Labeled loss: 0.8153 \t loss_o: -0.0048\n",
      "| Validation\t Net1  Acc: 74.36%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.73%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 87/100] Iter[800/800]\t  Labeled loss: 1.0774 \t loss_o: -0.0039\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 87/100] Iter[800/800]\t  Labeled loss: 0.6678 \t loss_o: -0.0031\n",
      "| Validation\t Net1  Acc: 74.62%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.99%\n",
      "| Saving Best Net2 ...\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 88/100] Iter[800/800]\t  Labeled loss: 1.1351 \t loss_o: -0.0040\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 88/100] Iter[800/800]\t  Labeled loss: 1.6874 \t loss_o: -0.0046\n",
      "| Validation\t Net1  Acc: 74.88%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.51%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 89/100] Iter[800/800]\t  Labeled loss: 0.9915 \t loss_o: -0.0050\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 89/100] Iter[800/800]\t  Labeled loss: 0.4286 \t loss_o: -0.0044\n",
      "| Validation\t Net1  Acc: 74.48%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.53%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 90/100] Iter[800/800]\t  Labeled loss: 0.8715 \t loss_o: -0.0033\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 90/100] Iter[800/800]\t  Labeled loss: 1.2548 \t loss_o: -0.0041\n",
      "| Validation\t Net1  Acc: 74.42%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.74%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 91/100] Iter[800/800]\t  Labeled loss: 0.9564 \t loss_o: -0.0042\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 91/100] Iter[800/800]\t  Labeled loss: 0.2669 \t loss_o: -0.0030\n",
      "| Validation\t Net1  Acc: 74.32%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.83%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 92/100] Iter[800/800]\t  Labeled loss: 0.9196 \t loss_o: -0.0046\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 92/100] Iter[800/800]\t  Labeled loss: 0.9281 \t loss_o: -0.0043\n",
      "| Validation\t Net1  Acc: 74.18%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.76%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 93/100] Iter[800/800]\t  Labeled loss: 1.4372 \t loss_o: -0.0019\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 93/100] Iter[800/800]\t  Labeled loss: 1.2581 \t loss_o: -0.0036\n",
      "| Validation\t Net1  Acc: 74.82%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.60%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 94/100] Iter[800/800]\t  Labeled loss: 1.4909 \t loss_o: -0.0043\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 94/100] Iter[800/800]\t  Labeled loss: 1.1624 \t loss_o: -0.0048\n",
      "| Validation\t Net1  Acc: 74.41%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.86%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 95/100] Iter[800/800]\t  Labeled loss: 0.6222 \t loss_o: -0.0039\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 95/100] Iter[800/800]\t  Labeled loss: 0.6662 \t loss_o: -0.0043\n",
      "| Validation\t Net1  Acc: 74.25%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.85%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 96/100] Iter[800/800]\t  Labeled loss: 1.3079 \t loss_o: -0.0032\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 96/100] Iter[800/800]\t  Labeled loss: 0.8319 \t loss_o: -0.0040\n",
      "| Validation\t Net1  Acc: 74.55%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.53%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 97/100] Iter[800/800]\t  Labeled loss: 1.2911 \t loss_o: -0.0046\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 97/100] Iter[800/800]\t  Labeled loss: 1.2720 \t loss_o: -0.0036\n",
      "| Validation\t Net1  Acc: 74.37%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.64%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 98/100] Iter[800/800]\t  Labeled loss: 0.4508 \t loss_o: -0.0022\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 98/100] Iter[800/800]\t  Labeled loss: 0.7549 \t loss_o: -0.0043\n",
      "| Validation\t Net1  Acc: 74.45%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.47%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 99/100] Iter[800/800]\t  Labeled loss: 0.4504 \t loss_o: -0.0036\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [ 99/100] Iter[800/800]\t  Labeled loss: 0.6797 \t loss_o: -0.0042\n",
      "| Validation\t Net1  Acc: 74.27%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.90%\n",
      "\n",
      "==== net 1 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "==== net 2 evaluate next epoch training data loss ====\n",
      "| Evaluating loss Iter 999\t\n",
      "\n",
      "Train Net1\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [100/100] Iter[800/800]\t  Labeled loss: 0.8186 \t loss_o: -0.0049\n",
      "Train Net2\n",
      "labeled data has a size of 25599\n",
      "unlabeled data has a size of 6401\n",
      "Clothing1M | Epoch [100/100] Iter[800/800]\t  Labeled loss: 0.4849 \t loss_o: -0.0045\n",
      "| Validation\t Net1  Acc: 74.41%\n",
      "\n",
      "| Validation\t Net2  Acc: 74.62%\n",
      "\n",
      "| Test Acc: 74.83%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = [0,0]\n",
    "for epoch in range(args.num_epochs+1):   \n",
    "        \n",
    "    if epoch<1:     # warm up  \n",
    "        warmup_dataset, train_loader = loader.run('warmup')\n",
    "        print('Warmup Net1')\n",
    "        warmup(net1,optimizer1,train_loader)     \n",
    "        warmup_dataset, train_loader = loader.run('warmup')\n",
    "        print('\\nWarmup Net2')\n",
    "        warmup(net2,optimizer2,train_loader)                  \n",
    "    else:      \n",
    "        print('\\n==== net 1 evaluate next epoch training data loss ====') \n",
    "        eval_dataset, eval_loader = loader.run('eval_train')  # evaluate training data loss for next epoch  \n",
    "        prob1,losses1,paths1 = eval_train(net1) \n",
    "        print('\\n==== net 2 evaluate next epoch training data loss ====') \n",
    "        eval_dataset, eval_loader = loader.run('eval_train')  \n",
    "        prob2,losses2,paths2 = eval_train(net2) \n",
    "                \n",
    "        thres_1 = np.sort(prob1)[int(args.num_batches*args.batch_size * args.nv)]\n",
    "        thres_2 = np.sort(prob2)[int(args.num_batches*args.batch_size * args.nv)]\n",
    "        \n",
    "        pred1 = (prob1 > thres_1)\n",
    "        pred2 = (prob2 > thres_2)      \n",
    "                \n",
    "        print('\\n\\nTrain Net1')\n",
    "        labeled_traindataset, labeled_trainloader, unlabeled_traindataset, unlabeled_trainloader = loader.run('train',pred2,prob2,paths=paths2) # co-divide\n",
    "        train(epoch,net1,net2,optimizer1,labeled_trainloader, unlabeled_trainloader,losses2)              # train net1\n",
    "        print('\\nTrain Net2')\n",
    "        labeled_traindataset, labeled_trainloader, unlabeled_traindataset, unlabeled_trainloader = loader.run('train',pred1,prob1,paths=paths1) # co-divide\n",
    "        train(epoch,net2,net1,optimizer2,labeled_trainloader, unlabeled_trainloader,losses1)              # train net2\n",
    "    \n",
    "    val_dataset, val_loader = loader.run('val') # validation\n",
    "    acc1 = val(net1,val_loader,1)\n",
    "    acc2 = val(net2,val_loader,2)   \n",
    "    \n",
    "    scheduler1.step()\n",
    "    scheduler2.step()    \n",
    "    \n",
    "    log.write('Validation Epoch:%d      Acc1:%.2f  Acc2:%.2f\\n'%(epoch,acc1,acc2))\n",
    "    log.flush() \n",
    "\n",
    "\n",
    "test_dataset, test_loader = loader.run('test')\n",
    "net1.load_state_dict(torch.load('./checkpoint/%s_net1.pth.tar'%args.id))\n",
    "net2.load_state_dict(torch.load('./checkpoint/%s_net2.pth.tar'%args.id))\n",
    "acc = test(net1,net2,test_loader)     \n",
    "\n",
    "\n",
    "\n",
    "log.write('Test Accuracy:%.2f\\n'%(acc))\n",
    "log.flush() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa910011-1cf4-4ac6-bd09-8089b07cdaaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74069a1-e91c-4982-a8eb-d49165bb6789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fdb38e-6291-4d7b-a464-ab84a9ae21f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f4de4-e89f-4669-b8ab-e345e99dc82f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
